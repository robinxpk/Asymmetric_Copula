---
title: 
output: 
  html_document:
    code_folding: hide
    css: styles.css
---
```{r, include=FALSE}
source("load_data.R")
source("functions.R")
knitr::opts_chunk$set(fig.width=14, fig.height=7, dpi=300, out.width="100%")
knitr::opts_knit$set(root.dir = normalizePath("."))
```


# Analysis {.tabset}

```{r}
# If mostly Vines are selected, it is interested how these look and how close they are to the actual, true model
# My simulation mostly goes to show how well these packages are applicable bzw. their implemented methods.
# Thus, my simulation is more of different models AND different methods which concludes to simulation to compare package performance
#     is okay, since I will apply these package to the data and not implement anything myself here

# Group the analysis by the true underlyding structure (ac, nac, vine). Then, show for each n, (and over the true copula family?) how
```

## Analysis NACs

```{r}

all_res = read_dep_files(true_dep = "nac", in_dir = "../data/simulation/")
attr(all_res, "B") = 2000 # For now since simulation does not contain B
attr(all_res, "sample sizes") = c(15, 30, 50, 1000)
attr(all_res, "copula families") = list("Clayton" = 3, "Gumbel" = 4, "Frank" = 5)
# Remove attributes that are no longer applicable
for (a in c("n", "true dep", "true cop")) attr(all_res, a) = NULL
sample_sizes = attr(all_res, "sample sizes")
B_nac = attr(all_res, "B")
copula_families = attr(all_res, "copula families")
```

### Sanity checks

```{r}
table(all_res$seed, all_res$cop, all_res$n) 
# Sanity check
nrow(all_res) # For each dependence structure: B seeds * length(sample_sizes) * length(copula_families)
B_nac * length(sample_sizes) * length(copula_families)

table(all_res$n) # Should be B * length(families) each
B_nac * length(copula_families)

table(all_res$cop) # B * length(sample_sizes)
B_nac * length(sample_sizes)

table(all_res$river) # Distribution of selected correlation; Should be equivalent to the number of different rivers I consider

# Checking for any NaNs
any(is.na(all_res))
# Investiage:
all_res[!complete.cases(all_res), ]
```
### KL Divergence

```{r}
# xxxxxxxxxxxxxx a) Copula fitting xxxxxxxxxxxxxxxxxxxxx
# >> Evaluation
# Start with 3. point so I can adjust data later on...
# 3) KL empirical density plot to evaluate how the other copula models perform under misspecification
clayton_kl = klplots(all_res, "Clayton", scales = "free")
plot(clayton_kl)
gumbel_kl = klplots(all_res, "Gumbel", scales = "free")
plot(gumbel_kl)
frank_kl = klplots(all_res, "Frank", scales = "free")
plot(frank_kl)
# Does the multimodality come from the different tau values (In AC)
# Vine and NACs perform pretty much identical for all sample sizes
# Reason: Vines are just more flexible such that NACs are somewhat a subset
# Important for us: Fitting Vine is reasonable for underlying structure being NAC
```
### Fit considerations

#### Retrieval of correct structure

```{r}
# 1) Retrieval of correct structure
#   Using AIC among these 3 dependence structures, how of (%) is the correct copula selected
all_res = all_res |>
  # Row wise, check which AIC is minimal
  dplyr::rowwise() |>
  dplyr::mutate(
    # Minimal AIC in Row (i.e. in simulated sample)
    min_aic = min(ac_aic, nac_aic, vine_aic),
    # Choice according to AIC
    choice_aic = dplyr::case_when(
      ac_aic == min_aic ~ "ac",
      nac_aic == min_aic ~ "nac",
      vine_aic == min_aic ~ "vine"
    ),
    choice_correct = choice_aic == dep
  ) |>
  dplyr::ungroup()

# Fraction correctly selected copula structure
mean(all_res$choice_correct)
# Marginal distribution of missclassifications
table(all_res$choice_aic)
# Behavior through sample size and copula
# table(all_res$choice_aic, all_res$n, all_res$cop)
prop.table(table(all_res$choice_aic, all_res$n, all_res$cop), margin = c(2, 3))
```

Separately consider cases where we chose correct structure and wrong strucutre.

When selection vine, i.e. wrong structure, how confident was our choice (judging by AIC).

There is one AIC ratio value that is uper large (around 12). Consider that one in detail later and filter it for now.
```{r}
wrg = all_res |>
  dplyr::filter(choice_aic == "vine") |>
  dplyr::mutate(aic_ratio =  vine_aic / nac_aic) |> 
  dplyr::filter(aic_ratio < 3)
```


```{r}
# Visualization of the above:
# How does AIC compare in those cases where vine was selected over NAC
# There is one insanely huge value: seed: 1099 n: 15 cop: Gumbel
wrg |> 
  ggplot(aes(y = aic_ratio)) +
  geom_boxplot()
# Judging by this plot, there are some times where the ratio between the AICs is quite large; i.e. we were quite confident in our vine selection
# That is, the AIC for vines is up to 1.6 times larger bzw. smaller than the AIC for NACs. That is quite a lot.
# When do these cases occure? How do  they change depending on sample size and copula?
```
Some decisions are pretty confident. How are we so confident in these cases? Are we overfitting? Consider KLD to consider if there is some bias or smth.


```{r}
clayton_kl = klplots(wrg, "Clayton", scales = "free")
plot(clayton_kl)
gumbel_kl = klplots(wrg, "Gumbel", scales = "free")
plot(gumbel_kl)
frank_kl = klplots(wrg, "Frank", scales = "free")
plot(frank_kl)
```
For small sample sizes (15) it does look like we have a small bias. 30 is okay. And after 30 everything is basically identical.

Bit difficult to see. Here mean and sd of the observed KL (not for AC bc its bad anyway)

```{r}
wrg |> 
  dplyr::summarise(
    # ac_mean = mean(ac_kl, na.rm = T),
    # ac_sd = sd(ac_kl, na.rm = T),
    nac_mean = mean(nac_kl, na.rm = T),
    vine_mean = mean(vine_kl, na.rm = T),
    nac_sd = sd(nac_kl, na.rm = T),
    vine_sd = sd(vine_kl, na.rm = T),
    .by = c(n, cop)
  )
```


How does confident in wrong structure behave for increasing sample sizes. 

```{r}
wrg |> 
  ggplot(aes(y = aic_ratio, x = cop)) +
  geom_boxplot() +
  facet_wrap(~ n)
# The AIC ratio mainly depends on the sample size and less on the copula family
# For our data, we move around 50 obs per stations, where the discrapency between the AICs is still sometimes up to a factor of 1.2
# That is, even we have a potentially large difference between NAC and Vine AIC, AIC selection might end up selecting the more complex structure
# However, as we have seen from the KL, both alternatives behave very similar in terms of approaching the true distribution
```
Since I want to only apply vines to the observed data, how do vines behave when AIC tells us to prefer NACs?
NOTE: Now aic ratio is nac AIC / vine AIC.
There is one that has factor of 500. Wtf. Look into that one later

```{r}
crt = all_res |>
  dplyr::filter(choice_correct == TRUE) |> 
  dplyr::mutate(aic_ratio =  abs(nac_aic / vine_aic)) |>  # Consider abs value bc there seems to be a change in sign for some AICs
  dplyr::filter(aic_ratio < 20)
```

```{r}
clayton_kl = klplots(crt, "Clayton", scales = "free")
plot(clayton_kl)
gumbel_kl = klplots(crt, "Gumbel", scales = "free")
plot(gumbel_kl)
frank_kl = klplots(crt, "Frank", scales = "free")
plot(frank_kl)
```
Similar as for wrong cases, only small sample sizes suggest a bit of an error choosing vines over NAC.

Here how confident we choose NACs over Vines:
```{r}
summary(crt$aic_ratio)
crt |> 
  ggplot(aes(y = aic_ratio)) +
  geom_boxplot()

```
Damn, sometimes we are super certain about NAC over Vines... How do vines performe if we are so super certain in NAC selection?

```{r}
quant = quantile(crt$aic_ratio, prob = 0.9)
confident = crt |> dplyr::filter(aic_ratio > quant)
```


We are mainly highly certain for very small sample sizes (15).

That is, the smaller the sample size, we are more confident in the true copula structure. We should keep that in mind for the applied part?

For small sample sizes, commpare NAC vs vines. The LARGER the aic_ratio in favor of NACs, the more confident we can be that the true 
structure is actually NAC!

```{r}
table(confident$n)
```
How KLD looks for when we would use vines even in cases where we confidently select NAC:

```{r}
# If a plot is missing, there are no cases for super confidence for those n
clayton_kl = klplots(confident, "Clayton", scales = "free")
plot(clayton_kl)
gumbel_kl = klplots(confident, "Gumbel", scales = "free")
plot(gumbel_kl)
frank_kl = klplots(confident, "Frank", scales = "free")
plot(frank_kl)
```


```{r}
# 2) MSE and Biases
#   Issue: MSE only defined between the true and estimated structure
#
#   Using the true parameters and the copula fitted in step 1, calc MSE for:
#   tau, copula param, tail dependence
#     (Added tail dep. bc it also should be a non-linear function of tau / theta and thus be biased?)
#   Interesting:
#   - How does sample size affect MSE (Bias and Variance)?
#   - How reliable are small sample estimates (variance for small samples)?
#   - Is there a bias in estimates due to Jensen's inequality
#
# 2) MSE in those cases, where the correct structure is selected
# To remove the variance in the true tau bzw. thetas, we consider the MSE for each true tau separately, i.e. for each river separately
# Note: Underlying is NAC, that is, HAC-package used --> theta was estimated
crt = crt |> 
  dplyr::rowwise() |>
  dplyr::mutate(
    theta_inner_diff = fit_theta_inner - true_theta_inner,
    theta_outer_diff = fit_theta_outer - true_theta_outer,
    tau_inner_diff = fit_tau_inner - true_tau_inner,
    tau_outer_diff = fit_tau_outer - true_tau_outer
  ) |>
  dplyr::ungroup() |>
  # TODO: During simulation, save which river the correlation structure is taken from. Here is a temp fix for now so I do not need to simulate all again:
  dplyr::mutate(
    river = dplyr::if_else(true_tau_inner == 0.8122395, "Donau", "Isar")
  )
```


```{r}
# Display differences
# Consider theta and tau separately bc different values. Also, tau is restricted onto -1 and 1, thus largest possible difference in 2
ldf = crt |>
  tidyr::pivot_longer(
    cols = contains("diff"),
    names_to = "est",
    values_to = "diff"
  ) |>
  dplyr::mutate(tau = grepl("tau", est, fixed = TRUE))
```


```{r}
# How does dependence structure affect the MSE in tau and theta? ----
# ## tau
ldf |> dplyr::filter(tau) |>
  ggplot(aes(y = diff, x = est)) +
  geom_boxplot() +
  facet_wrap(~ paste(river, cop), scale = "fixed")
# Deviations from the true tau all look somewhat identical among the different copula families and rivers
# Important: Cannot really observe a bias?
```


```{r}
# ## theta
ldf |> dplyr::filter(!tau) |>
  ggplot(aes(y = diff, x = est)) +
  geom_boxplot() +
  facet_wrap(~ paste(river, cop), scale = "fixed")
# Independent of the underlying dependence structure, the error seems to be dependent on the copula family
# But this may be due to skewness in the distribution which is hard to see in boxplots
```


```{r}
ldf |> dplyr::filter(!tau) |>
  ggplot(aes(x = diff, fill = est)) +
  geom_histogram(alpha = 0.6) +
  facet_wrap(~ paste(river, cop, scale = "fixed"))
# Does not really look like distributions are crazy skewed, but I am still not sure if a negative difference is just less likely due to
#   the range of the thetas
# How does sample size affect MSE ----
# -> From previously, it looked like the copula family affects the MSE. Thus, keep family as further effect "control"
```


```{r}
# ## tau
ldf |> dplyr::filter(tau) |>
  ggplot(aes(y = diff, x = est, color = cop)) +
  geom_boxplot() +
  facet_wrap(~ n, scale = "fixed")
# Basing the tau estimates on the functional form implied by the fitted model, we have a substantial error in the outer tau that only slowly decays
# But there still is no bias to observe -> Jensen's inequality does not seem to introduce a meaningful bias
```


```{r}
# ## theta
ldf |> dplyr::filter(!tau) |>
  ggplot(aes(y = diff, x = est, color = cop)) +
  geom_boxplot() +
  facet_wrap(~ n, scale = "fixed")
# Frank copula seems to be the most difficult to fit bzw. the most unreliable. However, the error in theta decays a lot faster than in tau
# Also, here the INNER theta seems to be of higher error compared to the outer theta. Not sure why?
# --> There does not seem to be a bias in any of the estimates. Thus, no bias due to Jensens
# --> The estimates of theta for small samples are somewhat reliable, however, the small sample estimates for tau based on the functional form are less reliable / high in variance
```


```{r}
# MSE table
crt |>
  dplyr::summarise(
    n = dplyr::n(), # number cases where specific river correlation structure was drawn
    mse_theta_inner = mean(theta_inner_diff^2),
    var_theta_inner = var(fit_theta_inner),
    bias_theta_inner = mse_theta_inner - var_theta_inner,

    mse_theta_outer = mean(theta_outer_diff^2),
    var_theta_outer = var(fit_theta_outer),
    bias_theta_outer = mse_theta_outer - var_theta_outer,

    mse_tau_inner = mean(tau_inner_diff^2),
    var_tau_inner = var(fit_tau_inner),
    bias_tau_inner = mse_tau_inner - var_tau_inner,

    mse_tau_outer = mean(tau_outer_diff^2),
    var_tau_outer = var(fit_tau_outer),
    bias_tau_outer = mse_tau_outer - var_tau_outer,

    .by = c(true_tau_inner, cop) # group by correlation (i.e. by river)
  )  |>
  dplyr::select(contains("mse"), contains("bias"))
# Also, depending on the copula FAMILY, we have changing theta values given a tau value
# Thus, we need to group by river AND copula family
# No fucking idea why the bias is negative. Cannot be. But it is so small, that it might be due to accumulation of computer inaccuracy in estimation?
# I just take it for now... I mean, based on the plots a bias of 0 is reasonable
```


```{r}
# Confirming AC estimate behavior in case of NACs
table(all_res$river, all_res$n)
all_res |>
  dplyr::mutate(seed = as.numeric(seed)) |>
  dplyr::group_by(river, n) |>
  dplyr::mutate(x = dplyr::row_number()) |>
  dplyr::ungroup() |>
  ggplot() +
  geom_ribbon(aes(ymin = true_tau_inner, ymax = true_tau_outer, x = x), fill = "lightblue", alpha = 0.2, color = "black") +
  geom_line(aes(y = ac_tau, x = x), color = "blue") +
  theme_minimal() +
  facet_grid(river ~ n, scale = "free_x", axes = "margins")
```

## Analysis Vines

```{r}
all_res = read_dep_files(true_dep = "vine", in_dir = "../data/simulation/") |>
  dplyr::mutate(
    true_famname_12 = get_vine_famname(true_fam_12),
    true_famname_13 = get_vine_famname(true_fam_13),
    true_famname_23 = get_vine_famname(true_fam_23),
    famcomb = as.factor(
      paste(
        substr(true_famname_12, start = 1, stop = 1),
        substr(true_famname_23, 1, 1),
        substr(true_famname_13, 1, 1),
        sep = "-"
      )
    )
  )
attr(all_res, "B") = 2000 # For now since simulation does not contain B
attr(all_res, "sample sizes") = c(15, 30, 50, 1000)
attr(all_res, "copula families") = list("Clayton" = 3, "Gumbel" = 4, "Frank" = 5)
# Remove attributes that are no longer applicable
for (a in c("n", "true dep", "true cop")) attr(all_res, a) = NULL
sample_sizes = attr(all_res, "sample sizes")
B_vine = attr(all_res, "B")
copula_families = attr(all_res, "copula families")
```


```{r}
table(all_res$river, all_res$n)
# Every family comb 1k for each sample size
table(all_res$famcomb, all_res$n)
```

### Sanity checks

Check if all observations are contained
```{r}
all(table(as.numeric(all_res$seed)) == length(sample_sizes))

# I care mostly about the stronger dependent variables, right?
# I care about fitting the correct copula family here and about the MSE for this one
# Accuracy in the other one is nice, but since the dependence structure is less severe anyway, it's not too relevant
# (i.e. getting something non-relvant off is not that severe)

# Sanity check
nrow(all_res) # Should be length(sample_size) * B
table(all_res$n) # Should be B each
table(all_res$river) # Distribution of selected correlation; Should be equivalent to the number of different rivers I consider
table(all_res$famcomb) # Realized family combinations

# Checking for any NaNs
any(is.na(all_res))
all_res[!complete.cases(all_res), ]
```
### KLD

```{r}
# xxxxxxxxxxxxxx a) Copula fitting xxxxxxxxxxxxxxxxxxxxx
# >> Evaluation
# Start with 3. point so I can adjust data later on...
# 3) KL empirical density plot to evaluate how the other copula models perform under misspecification
# KL by river (dependence structure)
all_res |>
    dplyr::select(n, river, contains("_kl")) |>
    tidyr::pivot_longer(
      cols = contains("_kl"),
      names_to = "dep",
      values_to = "kld"
    ) |>
  ggplot(aes(x = kld, color = dep)) +
  geom_density() +
  facet_wrap(~ river)
# Even under misspecification, in some cases, NACs perform okay. In other scenarios, they are clearly outperformed.
# One reason is probably that HAC not considers rotated fits, I think? But that goes to show its a shit package. 
# I will use vines in applied anyway, because:
# - Vines in both cases outperform NACs, which makes sense being for flexible !! Can I somehow check small sample size overfitting behavior of vines?
#   Overfitting due to flexibility would be only con
# - Even if NACs somewhat work, we still should not fit them since our observed data suggests 3 different degrees of dependence 
# - General advise against NACs: Their implementation in R is terrible while Vines work pretty well. 
#   This should not be a reason to not consider them at all, but one should consider the additional work due to NACs 
#   while still restricting oneself by the assumption of partial exchangeability. At that point, use vines.
```


```{r}
# KL by n
all_res |>
    dplyr::select(n, river, contains("_kl")) |>
    tidyr::pivot_longer(
      cols = contains("_kl"),
      names_to = "dep",
      values_to = "kld"
    ) |>
  ggplot(aes(x = kld, color = dep)) +
  geom_density() +
  facet_wrap(~ n)
```


```{r}
# KL by families
all_res |>
  dplyr::select(n, river, contains("_kl"), true_famname_12, famcomb) |>
  tidyr::pivot_longer(
      cols = contains("_kl"),
      names_to = "dep",
      values_to = "kld"
  ) |>
  # dplyr::filter(true_famname_12 == "Gumbel") |>
  # dplyr::filter(true_famname_12 == "Clayton") |>
  dplyr::filter(true_famname_12 == "Frank") |>
  ggplot(aes(x = kld, color = dep)) +
  geom_density() +
  facet_wrap(~ famcomb)


# Similar to examination of the tau estimates AC vs NAC: How do the NAC estimates behave if true is trivariate vine?




```

Behavior of NAC taus if Vine is true. (i.e. if only 2 relationships are estimated via NAC even tho its 3 unique relationships)

```{r}
all_res |> 
  dplyr::mutate(
    x = dplyr::row_number(),
    .by = c(river, n)
  ) |> 
  ggplot() +
  geom_line(aes(y = true_tau_12, x = x)) + 
  geom_line(aes(y = true_tau_23, x = x)) + 
  geom_line(aes(y = true_tau_13, x = x)) + 
  geom_line(aes(y = nac_tau_outer, x = x), color = "blue", alpha = 0.4) + 
  geom_line(aes(y = nac_tau_inner, x = x), color = "red", alpha = 0.4) + 
  facet_grid(n ~ river, scale = "free_x")
```
NAC seems to capture the two most strongly correlated relations. Thus, NACs totally overestimate the lowest strength of dependence by implying the same strength for the two lesser correlated variables. 
Thereby, the bias due to NAC under true vines increases the more different the two lower correlations are. 

Explains why KLD for the rivers is not too bad. Here, the two lower taus are somewhat similar. For the LowHighHigh case, the performance is worst because the difference between the lowest and 2nd lowest is largest.

Further consider the bias, i.e. systematically overestimating dependence strength for the lowest dependence strength.
Consider the relation between the true taus and the taus estimated by NAC. Relationship evaluated by fraction of NAC tau divided by true tau
From previous plot I expect:
a) The ratio of inner tau and largest tau is close to 1. That is, the inner tau in NAC models approximate the largest tau in vine copulas well
b) The ratio of outer tau and 2nd largest vine tau is close to 1. That is, the outer tau in NAC models approximte the 2nd largest tau well
c) The ratio of outer tau and smallest vine tau is large. That is, NAC are restricted to use the outer tau for this relationship too. Because it is close to 2nd largest tau, this ratio should be close to true_tau_medium / true_tau_small
```{r}
all_res |> 
  dplyr::mutate(
    inner_large = nac_tau_inner / true_tau_12, # tau_12 is largest (tree: 1 - 2 - 3)
    outer_med = nac_tau_outer / true_tau_23, # tau_23 is 2nd largest / medium dependence strength
    outer_small = nac_tau_outer / true_tau_13,
    .b = river
  ) |> 
  tidyr::pivot_longer(
    cols = c(inner_large, outer_med, outer_small),
    values_to = "val",
    names_to = "nest"
  ) |> 
  ggplot() + 
  geom_boxplot(aes(y = val, color = nest)) + 
  geom_hline(yintercept = 1, alpha = .7, linetype = 2) + 
  facet_grid(n~river)
```




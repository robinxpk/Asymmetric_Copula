---
output: pdf_document
bibliography: book.bib  
editor_options: 
  markdown: 
    wrap: 72
---

<!-- For now I used: https://bookdown.org/yihui/rmarkdown-cookbook/bibliography.html to cite -->

<!-- Github Repo: https://github.com/henrifnk/Seminar_ClimateNStatistics/blob/master/04-archimax.Rmd -->

<!-- Book: https://henrifnk.github.io/Seminar_ClimateNStatistics/ac.html#ref-durante2016 -->

Use: (see @nelsen2006, p. 1) or @nelsen2006 (p. 1)

# TODO: title {#title}

## TODOs:

TODO: Define an actual goal we want to achieve; \
Paper focuses on how much better asymmetric copulas are compared to symmetric ones\
Another goal could be that I use that paper
already showed FNAC are superior to common models, and I could compare
vine copulas (more flex) with FNACs. I expect not too much improvement
if we only focus on 3 variables, but we could extend our approach to
more than 3 and then see how they compare? Then I skip on all the
estimation theory and stuff?


TODO: Mention: "Sklar’s Theorem tells us that we can decompose any given
multivariate distribution function into its margins and a copula. By
this decomposition, copulas allow us to study multivariate distributions
functions independently of the margins" in "NACs meet R p. 1"

TODO: Mention "They [NACs] are able to capture different kinds of tail
dependencies, e.g., only upper tail dependence and no lower tail
dependence or both lower and upper tail dependence but of different
magnitude." in "NACs meet R p. 2"; But only if I want to introduce tail
dependence

TODO: POSSIBLE extension if time: vine copulas. Apparently they are less
restrictive than FNACs. Could see how they compare in performance (on
the real data tho) before considering to put vines into paper.

TODO: Mention "We assume continuous RVs only" All of the following only
holds for continuous RV;

TODO: I would like to compare rigid assumptions with more flexible ones.
But for now, I will only focus on the rigid, easier ones. Do the
flexible ones depending on the time I have.\
e.g.: no empirical pit yet, stick to theoretical pit. I will only apply
theoretical for now. After I see the data and check how much work
empirical will be, I change the content. NOTE: Psuedo-observations are
of empirical nature. i.e. they are calculated for a given data set.
Thus, the plots I create based on real world data display pseudo
observations. Also, the pseudo observations allow the construction of
the empirical copula.

TODO: The strong point about copulas is that the margins do not need to
belong to the same distributional family This is WHY they are strong at
all and this can also be seen from

TODO: Do I spell out numbers or not? For now, I will not spell out any
number

TODO: If I have space left, I can put the derivation of the relationship
between Kendall's tau and Copula (see p.86 in zhang), but derive it
myself by deriving P_C = 2 integral(copula)

TODO: If space left: I could expand the definition of "symmetry" in my
SAC section. There, I just state that symmetric SAC imply same degree of
dependence. However, I do not really say what symmetry is. Maybe
something like "SAC are function symmetric which implies only same
degrees of relationships are possible (SOURCE)"; see Nelsen p36 maybe

TODO: For outlook (or maybe in paper if I have the time) one could use
vine copulas (PCC; see p. 172 in zhang) as this approach is even
"free-er"

TODO: How is the derivative of a copula related to the conditional
copula?

*Author: TODO*

*Supervisor: Henri Funk*

```{r, echo=FALSE, include=FALSE, message=FALSE, warning=FALSE}
library(knitr)
library(kableExtra)
library(bookdown)
```

## Introduction {#intro}

Motivation from paper: (Abstract) Therea re 3 main characteristics of a
flood, i.e. trivariate distribution. Copulas allow to analyse trivariate
with no restrictions on marginals; I could go more detailled by listing
the restrictions of prebious approaches that required same marginals.
(essentially, copy p1156 middle of left side)

Copulas allow to define bivariate distribution conditioned on 3rd
variable. I WANT TO PLOT ONE OF THESE CONDITIONAL DENSITIES IN THE
PAPER. Triggers so hard that this is the goal but they never plotted it
(see what I mean in abstract of paper)

As @grimaldi2004 p. 1160 notes, because the three considered variables
are defined by the same physical phenomenon, we expect them to be
mutually correlated

### Hydrology basics

Explain all the variables we use in our analysis. e.g. look @grimaldi p
1160. Maybe we can also give an example hydrology graph and explain the
variables based on that. We should have one of those graphs anyway
because of the applied part in our analysis. ("caption like: FIG x shows
hydrology graph of river Y which we will look closer at in our later
analysis")

What is "traditional straight line method"?; Used in paper (see p.1163)
in Datenerhebung. In the end, it is not relevant... Only relevant how
our data is erhoben worden. ´

## Theory {#theory}

The first section gives a mathematical definition of copulas followed by
Sklar's Theorem which is crucial in copula theory and also helps to
understand the first sentences of my copula theory. lol.

### Copulas {#cops}

<!-- (see @grimaldi2005) - copula is a multivariate cdf defined in the unit -->

<!-- cube with standard uniform margins -->

@zhang2019 (p. 62) describe a copula as a cumulative distribution
function with standard uniform margins. The dimension $d$ of a copula
denotes the number of random variables it relates and hence there must
be at least two dimensions ($d \geq 2$).\
To give a mathematical definition, consider the vector
$u = (u_1, ..., u_d) \in \mathbb{R}^d$ where $u_j \in [0, 1]$ for
$j = \{1, .., d\}$. Then, a $d$ dimensional copula is defined by
@durante2016 (p. 14) as function $C:[0,1]^d\to [0,1]$ if, and only if,
the following conditions hold:

i)  $C(u_1, ..., u_d) = 0$ if $u_j = 0$ for at least one
    $j \in \{1,…,d\}$.

ii) $C(1, 1, ..., 1, u_j, 1, ..., 1) = u_j$

iii) $C$ is $d$-increasing

The first two conditions make up the boundary conditions of a $d$
copula. This notion is due to the fact the conditions use the least and
the greatest element in the domain of the copula, respectively (see
@nelsen2006, p. 9).

The first condition: the copula is "grounded" Based on @nelsen2016 (p.
9), this implies that setting just one variable its least possible value
yields the least possible value of the copula, no matter the other
variables.

The second condition: (@nelsen2006, p.9) By plugging in the greatest
possible element of the domain, we obtain the margins of the function
$C$.

The condition of $C$ to be $d$-increasing is cumbersome to map out in
higher dimensions, which is why we restrict our focus on $d = 2$. As we
will see later on, a $2$ dimensional point of view is sufficient for our
purposes anyway because we consider trivariate copulas in a nested way.
But more on that later.

According to @nelsen2006 (p. 8), the copula function $C$ is
$2$-increasing if for all $u_1, u_2, v_1, v_2 \in [0,1]$ with
$u_1 \leq u_2$ and $v_1 \leq v_2$: $$
C(u_2, v_2) - C(u_2, v_1) - C(u_1, v_2) + C(u_1, v_1) \geq 0
$$ Simply put, 2-increasing means that the volume under the copula
function over the rectangle $[u1, u2] \times [v_1, v_2]$ is
non-negative. This intuition can be translated into higher dimensions.

NOTE: In @zhang2019 p. 70 there also is a formulation of the conditions
for the trivariate case

In combination with groundedness, d-increasing implies nondecreasing in
each argument (@nelson2006, p. 9)

### Probability integral transform {#pit}

ADD SOURCES FOR MY STATEMENTS

The probability integral transform (pit) is a transformation that allows
to map any random variable $X$ into standard uniform space $U(0, 1)$.

It is a general theorem not specific to copulas as mentioned in
@durante2016 (p. 6), but it helps to understand Sklar's theorem.

The theorem is given by @hofert (p. 3): Let $F$ be a continuous CDF and
let random variable $X$ have CDF $F$, that is $X \sim F$. Then $F(X)$ is
a standard uniform random variable, that is, $F(X) \sim U(0, 1)$.

TODO: Empirical PIT
Empirical PIT is based on the empirical distribution function\
introduce pseudo-obs


<!-- Thus, pit provides the mechanism to transform the marginals into standard uniform variables, which is required by Sklar's Theorem.  -->

<!-- Pit is more of a prerequisit  -->

<!-- The copula utilizes these transformed variables to describe the dependence structure independent of the original marginals.  -->

### Identifying marginals
Can just drop this one if I choose vine. Then I only focus on the pseudo-obs

TODO

PIT requires knowledge of the marginals, unless empirical PIT is used..

What methods are available for this? Grimaldi mentions "Gringorten's
formula"

### Sklar's Theorem {#sklarstheorem}

<!-- @nelsen2006 (p. 1) introduces copulas as functions that join -->

<!-- multivariate distributions to their one-dimensional marginal -->

<!-- distributions. -->

<!-- <!-- that represent the dependence structure between random variables independent of the marginal distribution functions, allowing the multivariate distribution to be expressed in separated terms. -->

Sklar's Theorem is central to the theory of copulas because it proves
that any multivariate model can be constructed using copulas
(@nelsen2006 (p. 17), @durante2016, p. 42). Thereby, this theorem allows
to separate the representation of the dependence structure and marginal
distribution functions. The theorem is given by @nelsen2006 (p. 18):\
Let $F_{1,..,d}$ be a $d$-dimensional joint distribution function with
univariate margins $F_1, ..., F_d$. Then, there exists a $d$-dimensional
copula $C$ such that $$
F_{1, ..., d}(x_1, ..., x_d) = C(F_1(x_1), ..., F_d(x_d))\ \forall\ (x_1, ..., x_d)\in \mathbb{R}^d
$$ Where $C$ is unique if $F_1, ..., F_d$ are continuous. (And because
cdfs of continuous random variables are always continuous SOURCE (GPT so
far), our analysis deals with unique copulas.)

<!-- (continuous, but not "absolutely continuous") -->

<!-- continuous: no jumps in function -->

<!-- absolutely continous: no kinks in function bzw. function is differentiable everywhere -->

EQUATION NUMBER (Sklar's Theorem) allows two important conclusion. One,
any multivariate cdf can be expressed as a composition of a copula
function $C$ and the univariate margins $F_1, ..., F_d$. Thereby,
@zhang2019 (p. 66) conclude that $C$ connects the multivariate cdf to
its marginals which mean we can separately consider the marginal and the
joint behavior of variables and the problem of determining any
multivariate cdf is reduced to determining the copula. And two, the
marginal distributions do not need to be of the same family because
Sklar's theorem holds regardless. As mentioned earlier, this makes the
copula approach highly suitable for our purpose.

In this context, the derivation of the copula density is simple (see
@zhang2019, p. 66): $$
c(u_1, ..., u_d) = \frac{\partial C(u_1, ..., u_d)}{\partial u_1 ... \partial u_d} = \frac{f(x_1, ..., x_d)}{\Pi_{i = 1}^df_i(x_i)}
$$ where $f(x_1, ..., x_d)$ denotes the joint density of $X_1, ..., X_d$
and $f_i(x_i)$ the marginal density of $X_i$ for all
$i = \{1, ..., d\}$.

The copula density function is used to draw the contour lines in our
plots.

### Symmetric Archimedean copulas and the generator function {#archcops}

TODO: Do I only use one-parametric generator functions? IMO That depends
on the flexibility of R package and on how much work it is to work with
more (2) parametric families -\> Maybe check in simulation how useful 2
parametric families are and then decide later when I work on the real
data?

TODO: Give table of the relevant copulas / generator functions and
reference @zhang2019, p.129ff for further info on when some of them are
suitable?

TODO: Create that table of generator functions. We can just stick to the
functions given in the paper. I can also argue that way or just say "for
our analysis we stick to the copulas given in the paper"; might yield
the question "why not extent them". Keine Ahnung. Mach ich later.

As Nelsen (p. 109) states, symmetric Archimedean copulas (SACs) are
widely applied due their large variety (in the dependence structure they
allow) and easy construction. However, SACs only allow the same degree
of dependence among all possible pairs of variables as @zhang2019
(p.124) point out. This limits their use case. Thus, the next section
introduces fully nested Archimedean copulas (FNACs) which build on SACs
and which remove this restriction.\
As we see in this section, SACs are uniquely defined by their generator
function. Thus, we first give general idea of a generator, then the
representation of a copula in terms of the generator and finally some
specific functions that we will use in our later analysis.

Just like copulas, a generator is a function with certain properties.
That is, @nelsen2006 (p. 110, 111) defines a generator to be a
continuous and strictly decreasing function
$\phi: [0, 1] \to [0, \infty)$ such that $\phi(1) = 0$. Also, its
pseudo-inverse $\phi^{[-1]}:[0, \infty) \to [0, 1]$ is non-increasing on
$[0, \infty)$ and strictly decreasing on $[0, \phi(0)]$ and given by
@nelsen2006 (p. 110): $$
\phi^{[-1]}(t) = \begin{cases}
    \phi^{-1}(t) & \text{ if } 0 \leq t \leq \phi(0)\\
    0 & \text{ if } \phi(0) \leq t \lt \infty
\end{cases}
$$ The pseudo-inverse thereby allows more flexibility in the choice of
generator functions which becomes clear when considering strict
generators. A strict generator fulfills not only the above conditions,
but also $\phi(0) \to \infty$ (see @nelsen2006, p. 112). Then, the
pseudo-inverse simplifies to $\phi^{[-1]}(t) =\phi^{-1}(t)$. However, by
using the pseudo-inverse, non-strict generators are available to build a
copula.

TODO: Improve section on strict generators if I find myself also using
non-strict generators. Else, simplify this section to something like:\
"We only consider strict generators. Thus, our introduction of
generators will be restricted to their properties." And then do not
mention pseudo-inverse, but just the inverse thingy. (But I would like
to mention that in their case the pseudo-inverse simplifies to this one
inverse. Just to show I know that this is a special case... Not sure)

TODO: In our analysis we only focus on strict generator functions and
thus only refer to those as generators. DO I ONLY USE STRICT?? Wait for
real world data. In case I only use strict, I could also shorten this
section.

Finally, for a generator to yield a valid $d$-dimensional copula,
@grimaldi2004 and @zhang2019 (p. 124) mention that the pseudo-inverse
requires to be completely monotone which is given if the generator has
derivatives of all order with alternating sign: $$
(-1)^k \frac{d^k \phi^{[-1]}(t)}{dt^k} \geq 0
$$

While all generators fulfill above conditions, any specific generator is
determined by its functional form and its parameters. As we will see,
while the functional form is subject to assumption, parameter values
vary and influence the strength of dependence between variables. For our
analysis, we focus on generators defined by a single parameter $\theta$.

Now we are in the position to formulate the general representation of a
$d$-dimensional SAC in terms of a generator. For this purpose, we use
the vector $u$ from section @ref(#cops). Then, the relation is given by
@zhang2019 (p. 123): $$
C(u_1, ..., u_d) = \phi^{[-1]}\left( \sum^d_{j = 1} \phi(u_j) \right)
$$ (#eq:generatorSAC) This shows that SACs are uniquely defined by their
generator and can be constructed at will from any valid generator as
mentioned by @nelsen2006 (p. 110, 111, 114). It also shows that the
assumed function form of the generator translates to an assumed copula
family. The specific copula or dependence structure, respectively, is
then finally determined by the parameter value $\theta$. This is
essential because it implies that fitting a SAC to data is equivalent to
estimating the parameter of an assumed generator.\

<!-- TODO: Based on the copula representation in terms of generator, -->

<!-- @grimaldi2004 p1157 mentions that marginals of a $d$ copula are a $d-1$ -->

<!-- variate copula because $\phi(1) = 0$ which simply reduces the sum by one -->

<!-- term. This goes to show that setting one variable to 1 gives the $d-1$ -->

<!-- variate margin. -->

TODO: Do I want to keep the following:\
Additionally, equation (@ref:#eq:generatorSAC) shows that the arguments
to the SAC are exchangeable. According to @nelsen2006 (p. 38),
exchangeability is a form of symmetry and implies that the copula treats
all its arguments the same. Thus, the order of the input variables does
not affect the value of the copula. One conclusion from this
exchangeability is that SACs only allow the same degree of dependence,
as we already mentioned. This brings us to the next section on FNACs to
handle this restriction.

TODO: DO I want to keep this: (I think it is not that relevant because I
already have a reason to not use SACs anyway)\
@grimaldi2004 (p. 1157) mentions that for $d \gt 2$, are lower bounded
by the independence copula given by FORMULA. Thus, the multivariate SAC
can only display positive dependence for d larger 3.

<!-- In our paper, we focus on one-parameter generator functions as we will -->

<!-- introduce non-exchangeable (asymmetric) dependence across variable -->

<!-- groups by applying NACs (oder so to argue that I only use one-parametric -->

<!-- family); erstmal sag ich nichts dazu. Vielleicht nur "in our paper, we -->

<!-- focus on 1 parameter fams") -->

### Fully Nested Archimedean copulas {#nacs}

TODO: As I understand right now, the condition of increasing theta only yields valid NAC if from the same familty. i.e. copula family does not change within NAC, only the degree of dependence. (@hofer2016 p.2 "On strucutre.."). I could get around by arguing we want to compare NACs from papar with vine copulas. ie I would need to introduce vine copulas too....

As mentioned in the previous section, we overcome the limitation of SAC
by using FNACs which allow us to model asymmetric relationships.\
TODO: Write text here that like: First show what FNAC is, then give
conditions(the increasing dependence structure) and conclude on what
that means for practice.

FNACs are built by nesting bivariate SACs and @zhang2019 (p. 174) give
the $d$-dimensional representation in terms of the generator $$
C(u_1, ..., u_d) = \phi^{[-1]}_1 \left(  \phi_1 \circ \phi_2^{[-1]} \left( \phi_2 \circ ... \circ \phi^{[-1]}_{d-1}\left(\phi_{d-1}(u_1) + \phi_{d-1}(u_2)\right) + \phi_2(u_{d-1})  \right) + \phi_1(u_d) \right) \\
$$ (#eq:gFNAC) where $\circ$ represents the composition of functions.
@zhang2019 (p. 174) mentions that due to the nesting of generators, $2$
additional condition arise. First, $\phi_1^{-1}, ..., \phi^{-1}_{d-1}$
are required to be completely monotonic and, second, the composition of
functions $\omega_j = \phi_j \circ \phi_{j+1}$ belongs to the function
class $\mathit{L}^*_\infty$ defined as $$
\mathit{L}^*_\infty = \left\{ \omega:[0, \infty)\to [0, \infty)\ |\ \omega(0) = 0,\ \omega(\infty) = \infty,\ (-1)^{k-1}\frac{d^k\omega(t)}{dt^k} \geq 0; k = 1,...,\infty   \right\}
$$ Finally, @grimaldi2005 (p. 1157) mention that for equation
[ref\@eq](mailto:ref@eq){.email}:gFNAC to yield a valid copula, more
nested variables must have a stronger degree of dependence. That is, the
parameters of the generators $\phi_1, ..., \phi_{d-1}$ in equation
[ref\@eq](mailto:ref@eq){.email}:gFNAC must fulfill
$\theta_1 \leq ... \leq \theta_{d-1}$.\

We also express equation ref:gFNAC in terms of the copula function to
aid the understanding in the next paragraph. $$
C(u_1, ..., u_d)= C_1\left( C_2(...C_{d-2}(C_{d-1}(u_1, u_2), u_3)...), u_{d} \right)
$$ (#eq:cFNAC)

Equation ref:eq:gFNAC shows that FNACs allow different generator
functions $\phi_1,  ..., \phi_{d-1}$ where each has its own parameter
$\theta_1, ..., \theta_{d-1}$. In other words, every nested copula $j$
is able to have its own varying dependence structure via $\phi_j$ and
varying strength of dependence via $\theta_j$ which equation
ref:eq:cFNAC displays.\
As mentioned by @embrecht2003 (p. 375), the number of distinct
generators or bivariate copulas, respectively, is only $d-1$ while the
number of all possible pairs for $d$ variables is $\frac{d(d-1)}{2}$.
That is, FNACs only model $d-1$ distinct dependence structures. This
implies that FNACs do not consider the dependence structure for every
possible pair of the $d$ variables, but between a variable and a joint
distribution (SOURCE FOR THIS? I know I read this somewhere, but it is
also visible from the formula...). In fact, only for $u_1$ and $u_2$ the
direct dependence structure is considered.\
Thereby, exchangeability is lost, but partial exchangeability remains
because within the bivariate nested copulas, the two arguments are
interchangeable (see @embrecht2003 p. 375). So to a degree, symmetry
prefails.\
Finally, equation ref:gFNAC simplifies to ref:generatorsSAC for
$\phi_1 = ... = \phi_{d-1}$ and $\theta_1 = ... = \theta_{d-1}$, as
mentioned by @zhang2019 (p. 175). Thus, SACs are a special case of
FNACs.

Since we focus on trivariate copulas, we also formulate the FNAC
representation for $d = 3$ in terms of $C$: $$
C(u_1, u_2, u_3) = C_1(u_3, C_2(u_1, u_2))
$$

-   @grimaldi2004 notes that we have identical margins for $u_3$ and
    $u_1$ bzw. $u_2$ with $\phi_1^{[-1]}(\phi_1(u_3) + \phi(u_j))$. As
    mentioned above, this is due to the partial exchangeability.

For our analysis, we choose $5$ common trivariate FNACs which are
displayed in TABLE REF. The corresponding generators fulfill all listed
conditions such that the resulting copulas are valid (@grimaldi2004 p.
1157).


Also, we focus on copulas built by the same functional form in the generator. 
i.e. copula family does not change within the nested structure, but the parameters are allowed to vary.

In caption of copula table:\
zhang p. 175: Discusses/derives all trivariate asymmetric copulas ? Put
this table in SAC section?\
in "NACs meet R" p.4 is a table of generators. Like that more than the
full copula; On this page are also the restrictions on the parameters
for each generator\

### Kendall's $\tau$ {#kendallstau}

NOTE: If I do not like this section too much, check nelsen p. 157 for
another definition of concordance / discordance

NOTE: Another possible source is nelsen

According to @kendall1990 p.6, $\tau$ is a measure of association
between two random variables that distinguishes between concordance and
discordance. Concordance means that the two variables move in the same
direction while discordance means moving in opposite directions. This
becomes more clear by considering the probabilistic representation of
the theoretical value of Kendall's $\tau$ given by @zhang2019 (p. 85,
86) or @nelsen2006 (p. 158).\
Consider two continuous bivariate random vectors $X = (X_1, X_2)^T$ and
$X^* = (X^*_1, X^*_2)^T$ that are independent, but follow the same
distribution. From $X$ to $X^*$, the random variables $X_1$ and $X_1^*$
move in the same direction as $X_2$ and $X_2^*$ if
$(X_1 - X_1^*)(X_2 - X_2^*) > 0$. Because for the product to be larger
than $0$, the sign of both terms must be the same. Analogously,
discordance is given if $(X_1 - X_1^*)(X_2 - X_2^*) < 0$. Using $$
\mathbb{P}_{C} = \mathbb{P}\left(\left[(X_1 - X_1^*)(X_2 - X_2^*)\right] > 0 \right) \\
\mathbb{P}_D = \mathbb{P} \left( \left[ (X_1 - X_1^*)(X_2 - X_2^*)\right] < 0  \right)
$$

Kendalls's $\tau$ is given by:

$$
\tau(X_1, X_2) = \mathbb{P}_C - \mathbb{P}_D
$$Thus, Kendall's tau is difference in probailities of concordance and
discordance.

(#eq:pKendall)

Based on @ref(eq:pKendall), @zhang2019 (p. 86) and @nelsen2006 (p. 159,
161) show that Kendall's $\tau$ may be expressed in term of a bivariate
copula function.
<!-- This is the population value bzw. theoretical value of -->
<!-- Kendall's $\tau$ (see @nelsen p.162) -->

$$
\begin{align}
\tau(X_1, X_2) &=  4 \int_{[0, 1]^2} C(u, v)\ dC(u, v) - 1  \\
\tau(t)&= 4 \int_0^1 \frac{\phi(t)}{\phi'(t)}dt + 1
\end{align} 
$$ (#eq:cKendall)

As we can see from equation @ref(eq:cKendall), Kendall's $\tau$ - a
measure of association - can be expressed in terms of the copula
function only. It emphasizes once more that the copula captures the
whole dependence structure between variables independent of any marginal
distribution functions. An alternative representation of $\tau$ is in
terms of the generator. We will mostly use this relation to estimate
Kendall's $\tau$ under (wrongfully) assumed symmetry.

For SACs, we can express the copula in terms of the generator bzw.
dependence of the true parameter $\theta$ (see @nelsen2006 p. 162) The
general formula to express tau in terms of parameter of the generator is
given by @nelsen2006 p. 163 (This is the relationship between Kendall's
tau and the parameter(s) in the generator function)

TODO: Relationship Kendeall's tau, generator and parameter @zhang2019
p.134 and 128

<!-- @nelsen2006 p. 163 derives the Kendall distribution function. Let's see -->

<!-- how relevant that is. According to GPT: often used to estimate -->

<!-- parameters, can be used to compare theoretically implied Kendall -->

<!-- function with the empirical one (goodness of fit) in hierarchical models -->

<!-- it help to determine the dependence strength across variable subsets To -->

<!-- my understanding: Kendall function kind of entails the same info as the -->

<!-- copula itself as it is derived from it anyway. Thus it can be used for -->

<!-- parameter estimation and model diagnostics. But there are some upsides -->

<!-- to Kendall (GPT): Transforms the multivariate dependence structure into -->

<!-- a UNIVARIATE distribution. WTF! That sounds super good! This helps with -->

<!-- visualizing and all that! Also, it can provide how dependence across -->

<!-- NACs evolves. Sometimes allow more robust parameter estimation; is done -->

<!-- by minizing the difference between empirical and theoretical Kendall -->

<!-- distr. -->

Empirically, there are multiple versions of Kendall's $\tau$ depending
on the data structure. Since this paper focuses on continuous variables
only, we use the following formula given by @kendall1990 (p. 5): $$
t = \frac{P-Q}{\frac{1}{2}n(n-1)}
$$(#eq:eKendall)

Where $P$ denotes the number of concordant and $Q$ the number of
discordant pairs in the data.

Significance test:\
Formula @hollander2015 p. 396, formula 8.13 (case of no ties which is fine bc continuous variables)\
cor.test with method = kendall implements this as seen in @hollander2015 p. 398, 399\
Do I only mention the formula for the test here and implementation in the implementation and package chapter?

### Estimation process
Introduce MLE

Check how HAC does it 

## Diagnostics and Goodness of fit evaluation

See @zhang2019 in chapter 3, 4, 5 I think. Also regarding MLE AIC

GOF in paper: 
Test by Chen (source 3)
Visual comparison
likelihood profile confidence intervals (source 4)



A common method to evalute goodness of fit is Kendall's distribution
function. However, as @zhangPAPER mention, this expression is
complicated to handle in the trivariate case which is why we introduce
the following methods instead.

### AIC / BIC

## Used packages and programming language

I use R

Used package copula

THESE FUNCTIONS implement are the (exact) implementation of what we
presented in theory

THESE FUNCTIONS give the nested copulas of the mentioned families which
are used for data simulation (and estimation?)

For estimation, the HAC package in R. According to @okhrin in HAC DOKU, the central contribution of this package is the parameter and structure estimation. 


## Simulation

TODO: Check the other papers before simulating to know which diagnostics
I can run

BEFORE ADDING ANYTHING TO MY THEORY PART, CHECK IMPLEMENTATION IN
R!!!!!!!!!!!

Applied I want to:\
0) Proof that dependence exists\
test for kendalls tau (TODO: Add to theroy)\
1) Identify margins  Check paper for this method thing + empirical PIT
(TODO: Add both to theory part)\
2) Identify dependence structue / copula based on pseudo-obs\
model fitting (MLE) (TODO: Add ML to theory) (Estimation of parameters
(Paper: Canonical maximum likelihood; thus, this one must be applicable
for nested); see surces 5 and 15 in grimaldi paper)\
3) If multiple copulas fitted, choose one / validation of chosen\
i.e. model / copula choice. AIC + Check papers (TODO: Add possibilities
to theory) Goodness of fit in paper by zhang: AIC, Kolmogorov and root
mean square error\
Copula selection: Visually, Chen's test (see source 3 in paper)\
After fitting copula, simulate 5k data points and check how things
allign (Fig 6) (validation)\
4) Determine conditional distribution of interest\
TODO: Check how to and add to theory

TODO: Check behavior of my chosen methods for different settings:\
- varying sample size\
- Compare bahavior by different dependence structure i.e. different
copulas\
- Compare PIT based on assumption (correct and wrong) and empirical PIT\
C- ramér-von Mises test, Kolmogorov-Smirnov test, or Rosenblatt
transform-based test\
- Try some different copulas and check the scatter plots. Like in paper
or check nelsen2006 p.120ff\

Also, copy what paper does: How does fit behave if we assume symmetric,
but it is non-symmetric\
Effect of varying degrees of dependence (on the symmetric assumption,
but extend this for me)\
TODO: Display wise we adapt @grimaldi2004 and display theoretical values
theta1 and theta2 as well as theta_symm which is MLE estimate under the
correct copula function, but the assumption of theta1 = theta2 which is
of course wrong in the asymmetric case. We use Kendall's $\tau$ to
assess the dependence between variables where $\tau_1$ denotes the more
strongly dependent variable and $\tau_2$ the average of weaker
correlated variables. $\tau_{symm}$ is the symmetric Kendall's $\tau$
using equation NUMBER and the estimated $theta_{symm}$.\
GOAL: tau_symm is closer to tau_1 and thus wrong symmetry assumption
overestimates the dependence between variables (which corresponds to the
findings the grimaldi who dives more deeply into this. We focus on
comparing the performance for different approahces now -\> follow with
examination of different approahces / wrong assumptions etc.

Goal of this section is to examine how the copula approach behaves under
varying circumstances like wrong assumptions and non-parametric (is
empirical PIT non-parametric?) approaches. Note: I expect emprical PIT
to perform better if assumption on marginal is wrong, else I expect it
to be less powerful.

Start with M6 copula (the one that is also displayed in paper);
asymmetric Gumbel copula; 5k observations

TODO: Mention again that for decreasing dependence structure no samples
can be generated bc nested copula requires increasing dependence by
increasing nested. Also from above, we know that for 3 variables, only 2
possible dependence structure exists due to nested. Thus, I only need 2
out of 3 plots or I plot 3 and again point out why 2 of them look the
same.

## Application

TODO: Show that dependence structure is indeed non-symmetric; i.e.
transform to copula and show that different dependence strucutre. Can
show this on the "best fitting copula", like: Figure X shows that
dependence structure is indeed asymmetric where FIG X is based on copula
xy which is best fitting according to our measures as we will see in the
following section; oder so.

Note: See example data set in table 2 of grimaldi paper

Note: See Fig 4 for potential display of Kendall's $\tau$ over
severeness of flood

Note:

## References {#ref}

::: {#refs}
:::
